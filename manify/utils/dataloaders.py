"""# Dataloaders Submodule.

The dataloaders module allows users to load datasets from Manify's datasets repo [on Hugging Face](https://huggingface.co/manify).

We provide a summary of the data types available, and their original sources, here.

Earlier versions of Manify included scripts to process raw data, which we have replaced with a single, centralized Hugging Face repo and the function `load_hf`. For transparency, we have preserved the data generation code in [the Dataset-Generation branch of Manify](https://github.com/pchlenski/manify/tree/Dataset-Generation).

| Dataset | Task | Distance Matrix | Features | Labels | Adjacency Matrix | Source/Citation |
|---------|------|----------------|----------|--------|-----------------|-----------------|
| cities | none | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | [Network Repository: Cities](https://networkrepository.com/Cities.php) |
| cs_phds | regression | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ | [Network Repository: CS PhDs](https://networkrepository.com/CSphd.php) |
| polblogs | classification | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ | [Network Repository: Polblogs](https://networkrepository.com/polblogs.php) |
| polbooks | classification | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ | [Network Repository: Polbooks](https://networkrepository.com/polbooks.php) |
| cora | classification | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ | [Network Repository: Cora](https://networkrepository.com/cora.php) |
| citeseer | classification | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ | [Network Repository: Citeseer](https://networkrepository.com/citeseer.php) |
| karate_club | none | ‚úÖ | ‚ùå | ‚ùå | ‚úÖ | [Network Repository: Karate](https://networkrepository.com/karate.php) |
| lesmis | none | ‚úÖ | ‚ùå | ‚ùå | ‚úÖ | [Network Repository: Lesmis](https://networkrepository.com/lesmis.php) |
| adjnoun | none | ‚úÖ | ‚ùå | ‚ùå | ‚úÖ | [Network Repository: Adjnoun](https://networkrepository.com/adjnoun.php) |
| football | none | ‚úÖ | ‚ùå | ‚ùå | ‚úÖ | [Network Repository: Football](https://networkrepository.com/football.php) |
| dolphins | none | ‚úÖ | ‚ùå | ‚ùå | ‚úÖ | [Network Repository: Dolphins](https://networkrepository.com/dolphins.php) |
| blood_cells | classification | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå | See datasets from Zheng et al (2017): Massively parallel digital transcriptional profiling of single cells.<br>- [CD8+ Cytotoxic T-cells](https://www.10xgenomics.com/datasets/cd-8-plus-cytotoxic-t-cells-1-standard-1-1-0)<br>- [CD8+/CD45RA+ Naive Cytotoxic T Cells](https://www.10xgenomics.com/datasets/cd-8-plus-cd-45-r-aplus-naive-cytotoxic-t-cells-1-standard-1-1-0)<br>- [CD56+ Natural Killer Cells](https://www.10xgenomics.com/datasets/cd-56-plus-natural-killer-cells-1-standard-1-1-0)<br>- [CD4+ Helper T Cells](https://www.10xgenomics.com/datasets/cd-4-plus-helper-t-cells-1-standard-1-1-0)<br>- [CD4+/CD45RO+ Memory T Cells](https://www.10xgenomics.com/datasets/cd-4-plus-cd-45-r-oplus-memory-t-cells-1-standard-1-1-0)<br>- [CD4+/CD45RA+/CD25- Naive T Cells](https://www.10xgenomics.com/datasets/cd-4-plus-cd-45-r-aplus-cd-25-naive-t-cells-1-standard-1-1-0)<br>- [CD4+/CD25+ Regulatory T Cells](https://www.10xgenomics.com/datasets/cd-4-plus-cd-25-plus-regulatory-t-cells-1-standard-1-1-0)<br>- [CD34+ Cells](https://www.10xgenomics.com/datasets/cd-34-plus-cells-1-standard-1-1-0)<br>- [CD19+ B Cells](https://www.10xgenomics.com/datasets/cd-19-plus-b-cells-1-standard-1-1-0)<br>- [CD14+ Monocytes](https://www.10xgenomics.com/datasets/cd-14-plus-monocytes-1-standard-1-1-0) |
| lymphoma | classification | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå | See datasets from 10x Genomics:<br>- [Hodgkin's Lymphoma](https://www.10xgenomics.com/datasets/hodgkins-lymphoma-dissociated-tumor-targeted-immunology-panel-3-1-standard-4-0-0)<br>- [Healthy Donor PBMCs](https://www.10xgenomics.com/datasets/pbm-cs-from-a-healthy-donor-targeted-compare-immunology-panel-3-1-standard-4-0-0) |
| cifar_100 | classification | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå | [Hugging Face Datasets: CIFAR-100](https://huggingface.co/datasets/uoft-cs/cifar100) |
| mnist | classification | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå | [Hugging Face Datasets: MNIST](https://huggingface.co/datasets/ylecun/mnist) |
| temperature | regression | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå | [Citation] |
| landmasses | classification | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå | Generated using [basemap.is_land](https://matplotlib.org/basemap/stable/api/basemap_api.html#mpl_toolkits.basemap.Basemap.is_land) |
| neuron_33 | classification | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå | [Allen Brain Atlas](https://celltypes.brain-map.org/experiment/electrophysiology/623474400) |
| neuron_46 | classification | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå | [Allen Brain Atlas](https://celltypes.brain-map.org/experiment/electrophysiology/623474400) |
| traffic | regression | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå | [Kaggle: Traffic Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/traffic-prediction-dataset) |
| qiita | none | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | [NeuroSEED Git Repo](https://github.com/gcorso/NeuroSEED) |
"""

from __future__ import annotations
from typing import TYPE_CHECKING
import torch
from datasets import load_dataset

if TYPE_CHECKING:
    from jaxtyping import Float, Real


def load_hf(
    name: str, namespace: str = "manify"
) -> tuple[
    Float[torch.Tensor, "n_points ..."] | None,  # features
    Float[torch.Tensor, "n_points n_points"] | None,  # pairwise dists
    Float[torch.Tensor, "n_points n_points"] | None,  # adjacency
    Real[torch.Tensor, "n_points"] | None,  # labels
]:
    """
    Load a dataset from HuggingFace Hub at {namespace}/{name}, or from PyG if name='pubmed'.
    """
    # ‚úÖ Êñ∞Â¢ûÂàÜÊîØÔºöPubMed Êï∞ÊçÆÈõÜ
    if name.lower() == "pubmed":
        print("üìò Loading PubMed dataset using PyTorch Geometric ...")
        from torch_geometric.datasets import Planetoid
        from torch_geometric.utils import to_dense_adj
        import time

        start_time = time.time()
        dataset = Planetoid(root="data/PubMed", name="PubMed")
        data = dataset[0]

        features = data.x
        labels = data.y
        adj = to_dense_adj(data.edge_index)[0]

        print(f"‚úÖ Loaded raw PubMed tensors: features {features.shape}, adj {adj.shape}, labels {labels.shape}")

        # ËÆ°ÁÆó pairwise Ê¨ßÂºèË∑ùÁ¶ªÁü©Èòµ
        with torch.no_grad():
            try:
                print(" Computing pairwise distance matrix...")
                dists = torch.cdist(features, features)
            except RuntimeError:
                subset = 1000
                print(f" ÂÜÖÂ≠ò‰∏çË∂≥ÔºåÊäΩÊ†∑Ââç {subset} ‰∏™ËäÇÁÇπËÆ°ÁÆóË∑ùÁ¶ªÁü©Èòµ")
                features = features[:subset]
                labels = labels[:subset]
                adj = adj[:subset, :subset]
                dists = torch.cdist(features, features)

        elapsed = time.time() - start_time
        print(f" PubMed dataset loaded in {elapsed:.2f} seconds")
        print(f"ËäÇÁÇπÊï∞: {features.shape[0]}, ÁâπÂæÅÁª¥Â∫¶: {features.shape[1]}, Á±ªÂà´Êï∞: {len(torch.unique(labels))}\n")

        return features, dists, adj, labels
    
    #COMPUTERS dataset
    elif name.lower() == "computers":
        print("üìò Loading Amazon Computers dataset using PyTorch Geometric ...")
        from torch_geometric.datasets import Amazon
        dataset = Amazon(root="data/Computers", name="Computers")
        data = dataset[0]

    # adjacency matrix
        adj = torch.zeros((data.num_nodes, data.num_nodes), dtype=torch.float32)
        edges = data.edge_index
        adj[edges[0], edges[1]] = 1
        adj[edges[1], edges[0]] = 1  # Êó†ÂêëÂõæ

    # ËÆ°ÁÆó pairwise Ë∑ùÁ¶ªÁü©ÈòµÔºàÁÆÄÂçïÁâàÔºöÁî®ÁâπÂæÅÊ¨ßÊ∞èË∑ùÁ¶ªÔºâ
        print("Computing pairwise distance matrix (features-based)...")
        features = data.x
        dists = torch.cdist(features, features, p=2)

        features = features.float()
        labels = data.y.long()
        print(" Amazon Computers dataset loaded successfully!")
        return features, dists, adj, labels


    # ‚úÖ ÂéüÂßãÈÄªËæëÔºàHugging Face Êï∞ÊçÆÈõÜÔºâ
    ds = load_dataset(f"{namespace}/{name}")
    data = ds.get("train", ds)  # use "train" split if available, else the only split
    row = data[0]

    def to_tensor(key: str, dtype: torch.dtype) -> torch.Tensor | None:
        vals = row.get(key, [])
        if not vals:
            return None
        return torch.tensor(vals, dtype=dtype)

    dists = to_tensor("distances", torch.float32)
    feats = to_tensor("features", torch.float32)
    adj = to_tensor("adjacency", torch.float32)

    cls_ls = row.get("classification_labels", [])
    reg_ls = row.get("regression_labels", [])
    if cls_ls:
        labels = torch.tensor(cls_ls, dtype=torch.int64)
    elif reg_ls:
        labels = torch.tensor(reg_ls, dtype=torch.float32)
    else:
        labels = None

    return feats, dists, adj, labels